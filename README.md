# Commentaires toxiques
Ce projet vise à classer la toxicité de commentaires issus de Kaggle du "Toxic Comment Classification Challenge".
Ces commentaires doivent être classés sur 6 catégories : toxic, severe_toxic, obscene, threat, insult, identity_hate.

# Utilisation
Le notebook final se trouve dans la branche main.
Une fois que les données Kaggle sont téléchargées dans un google drive il suffit d'ouvrir le notebook présent dans la branche "main" avec Google Collab.

Nous avons travaillé avec :
Google Colab
tensorflow: 2.11.0
Python: 3.8.10

# Membres du projet
Ce projet est réalisé par [Rodolphe Maury](https://github.com/KuribohAile) et [Célestin Captal](https://github.com/cc-ca).
